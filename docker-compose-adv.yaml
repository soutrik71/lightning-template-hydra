version: '3.8'

services:
  train:
    build:
      context: .
    command: |
      python -m src.train
    volumes:
      - data:/app/data
      - checkpoints:/app/checkpoints
      - artifacts:/app/artifacts
    shm_size: '4g'  # Shared memory size for large datasets
    networks:
      - default
    env_file:
      - .env  # Load environment variables

  eval:
    build:
      context: .
    command: |
      /bin/bash -c "while [ ! -f /app/checkpoints/train_done.flag ]; do sleep 10; done;
      python -m src.eval"
    volumes:
      - data:/app/data
      - checkpoints:/app/checkpoints
      - artifacts:/app/artifacts
    shm_size: '4g'
    networks:
      - default
    depends_on:
      - train  # Ensure train runs before eval
    env_file:
      - .env  

  inference:
    build:
      context: .
    command: |
      /bin/bash -c "while [ ! -f /app/checkpoints/train_done.flag ]; do sleep 10; done;
      python -m src.infer"
    volumes:
      - data:/app/data
      - checkpoints:/app/checkpoints
      - artifacts:/app/artifacts
    shm_size: '4g'
    networks:
      - default
    depends_on:
      - train  # Ensure train runs before inference
    env_file:
      - .env  

volumes:
  data:
  checkpoints:
  artifacts:

networks:
  default:
